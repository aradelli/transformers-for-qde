{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10638,
     "status": "ok",
     "timestamp": 1605107185185,
     "user": {
      "displayName": "Giovanni Aradelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzto1ysV8aaZPkZLX1nLKwD5iZBJjEQjXRrC_fAA=s64",
      "userId": "05802898670150988825"
     },
     "user_tz": -60
    },
    "id": "haEenvuAwhb_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModel,\n",
    "    TFAutoModelWithLMHead\n",
    ")\n",
    "\n",
    "QUESTION_ID = 'problem_id'\n",
    "QUESTION_TEXT = 'body'\n",
    "DIFFICULTY_KEY = 'difficulty'\n",
    "\n",
    "\n",
    "# read data\n",
    "DATA_PATH = 'data/'\n",
    "# question stem + difficulty\n",
    "df = pd.read_csv(DATA_PATH + 'text_difficulty.csv')\n",
    "# delete duplicate texts, if any.\n",
    "df.drop_duplicates(subset=QUESTION_TEXT, keep=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1788253,
     "status": "error",
     "timestamp": 1605114606494,
     "user": {
      "displayName": "Giovanni Aradelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzto1ysV8aaZPkZLX1nLKwD5iZBJjEQjXRrC_fAA=s64",
      "userId": "05802898670150988825"
     },
     "user_tz": -60
    },
    "id": "wFS0RNxhEfrM",
    "outputId": "4b32f176-6698-4cd3-80f8-a2a1e9ca4d38"
   },
   "outputs": [],
   "source": [
    "def create_model(model_name, max_length=128, dropout_intern=0.5, dropout_final=0.5):\n",
    "    \"\"\"\n",
    "    It creates the model composed by transformer, specified by model name, + top layers to do regression.\n",
    "    @param dropout_final: the dropout of the fully connected layer on the top of the transformer\n",
    "    @param dropout_intern the dropout for fully connected layers in the transformer\n",
    "    @param max_length: max sequence length\n",
    "    @param model_name: the name of the huggingface model\n",
    "    @return: tf.keras model\n",
    "    \"\"\"\n",
    "    # import pre trained model to fine tune\n",
    "    transformer_model = TFAutoModel.from_pretrained(model_name)\n",
    "    # specify INTERNAL dropout of the pre trained model\n",
    "    transformer_model.config.dropout = dropout_intern\n",
    "    # input of the model\n",
    "    input_ids = tf.keras.layers.Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
    "    # take the last hidden layer of shape (batch_size, sequence_length, hidden_size = 768))\n",
    "    embedding_layer = transformer_model([input_ids])[0]\n",
    "    # take the only embeddings of CLS token\n",
    "    cls_token = embedding_layer[:, 0, :]\n",
    "    dropout = tf.keras.layers.Dropout(dropout_final)(cls_token)\n",
    "    # output layer 1 neuron linear activation function (default one) since we are performing regression\n",
    "    output = tf.keras.layers.Dense(1)(dropout)\n",
    "    model = tf.keras.Model(inputs=[input_ids], outputs=output)\n",
    "    # set optimizer\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=LR)\n",
    "    # set MAE as loss\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    # set other metrics\n",
    "    metric1 = tf.keras.metrics.MeanAbsoluteError()\n",
    "    metric2 = tf.keras.metrics.RootMeanSquaredError()\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=loss,\n",
    "                  metrics=[metric1, metric2])\n",
    "    # return tf.keras.model\n",
    "    return model\n",
    "\n",
    "\n",
    "def encode(\n",
    "        samples,\n",
    "        tokenizer,\n",
    "        max_length=256,\n",
    "):\n",
    "    \"\"\"\n",
    "    It encodes the textual information of the questions using the tokenizer\n",
    "    @param samples: list of tuple tuple (textual information, target difficulty)\n",
    "    @param tokenizer: the tokenizer\n",
    "    @param max_length: max sequence length\n",
    "    @return:\n",
    "            encoded_text: list of encoded text x\n",
    "            target_difficulty: list of target difficulty y\n",
    "    \"\"\"\n",
    "    encoded_text = []\n",
    "    target_difficulty = []\n",
    "    for t in samples:\n",
    "        text, target = t\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,  # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True,  # pads to the right by default\n",
    "            truncation='longest_first'\n",
    "        )\n",
    "        encoded_text.append(input_dict['input_ids'])\n",
    "        target_difficulty.append(target)\n",
    "    return encoded_text, target_difficulty\n",
    "\n",
    "\n",
    "def load_mlm_model_weights(model, model_name,\n",
    "                           path='/tf_model.h5'):\n",
    "    \"\"\"\n",
    "    @param model: tf.keras model to set the weights to\n",
    "    @param model_name: the name of the huggingface model\n",
    "    @param path: file path containing the weights in format .h5\n",
    "    @return: tf.keras model with the new weights\n",
    "    \"\"\"\n",
    "    mlm_model = TFAutoModelWithLMHead.from_pretrained(model_name)\n",
    "    mlm_model.load_weights(path)\n",
    "    # set the pre-trained weights to the 'transformer' layer (see model.summary())\n",
    "    model.layers[1].set_weights(mlm_model.layers[0].get_weights())\n",
    "    return model\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "SEED_SPLIT_DATASET = 1234\n",
    "EPOCHS = 35\n",
    "MAX_LENGTH = 128\n",
    "LR = 1e-5\n",
    "DROPOUT_FINAL = 0.5\n",
    "DROPOUT_INTERN = 0.25\n",
    "MODEL_TO_FT = 'bert-base-uncased'\n",
    "PATIENCE = 10\n",
    "LOAD_MLM_WEIGHTS = False  # True to use the weights of MLM fine-tuned model\n",
    "TPU = False\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "if TPU:\n",
    "    # Create strategy from tpu\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    BATCH_SIZE = BATCH_SIZE * strategy.num_replicas_in_sync\n",
    "\n",
    "# train, validation, test split\n",
    "train, test = train_test_split(df[QUESTION_ID], test_size=0.2, random_state=SEED_SPLIT_DATASET)\n",
    "df_train = df[df[QUESTION_ID].isin(train)]\n",
    "df_test = df[df[QUESTION_ID].isin(test)]\n",
    "train, validation = train_test_split(df_train[QUESTION_ID], test_size=0.1, random_state=SEED_SPLIT_DATASET)\n",
    "df_train = df[df[QUESTION_ID].isin(train)]\n",
    "df_validation = df[df[QUESTION_ID].isin(validation)]\n",
    "\n",
    "test = list(zip(df_test[QUESTION_TEXT], df_test[DIFFICULTY_KEY]))\n",
    "train = list(zip(df_train[QUESTION_TEXT], df_train[DIFFICULTY_KEY]))\n",
    "validation = list(zip(df_validation[QUESTION_TEXT], df_validation[DIFFICULTY_KEY]))\n",
    "\n",
    "train_length = len(train)\n",
    "\n",
    "print('#train', len(train))\n",
    "print('#test', len(test))\n",
    "print('#validation', len(validation))\n",
    "\n",
    "# define the tokenizer specific for the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_TO_FT)\n",
    "\n",
    "# encode the data\n",
    "x_train, y_train = encode(train, tokenizer, max_length=MAX_LENGTH)\n",
    "x_test, y_test = encode(test, tokenizer, max_length=MAX_LENGTH)\n",
    "x_val, y_val = encode(validation, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "# transform the dataset into a tf.dataset\n",
    "train_data = (\n",
    "    tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, y_train))\n",
    "        .repeat(-1)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    ")\n",
    "valid_data = (\n",
    "    tf.data.Dataset\n",
    "        .from_tensor_slices((x_val, y_val))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    ")\n",
    "test_data = (\n",
    "    tf.data.Dataset\n",
    "        .from_tensor_slices((x_test, y_test))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "\n",
    "# callback for early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=PATIENCE,\n",
    "                                            restore_best_weights=True)\n",
    "# set train_steps in order to go through all the train ds\n",
    "train_steps = train_length // BATCH_SIZE\n",
    "\n",
    "# list of random seeds\n",
    "seeds = [1,2,3]\n",
    "# lists to store the results\n",
    "train_result_T = []\n",
    "valid_result_T = []\n",
    "test_result_T = []\n",
    "test_extremes_result_T = []\n",
    "\n",
    "# repeat the training len(seeds) times\n",
    "for SEED_TF in seeds:\n",
    "    # set various SEED\n",
    "    np.random.seed(SEED_TF)\n",
    "    tf.random.set_seed(SEED_TF)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = str(SEED_TF)\n",
    "\n",
    "    if TPU:\n",
    "      with strategy.scope():\n",
    "          model = create_model(model_name=MODEL_TO_FT, dropout_intern=DROPOUT_INTERN, dropout_final=DROPOUT_FINAL,\n",
    "                             max_length=MAX_LENGTH)\n",
    "    else:\n",
    "         model = create_model(model_name=MODEL_TO_FT, dropout_intern=DROPOUT_INTERN, dropout_final=DROPOUT_FINAL,\n",
    "                         max_length=MAX_LENGTH)\n",
    "\n",
    "    # to set mlm weights to our model\n",
    "    if LOAD_MLM_WEIGHTS:\n",
    "        model = load_mlm_model_weights(model, model_name=MODEL_TO_FT)\n",
    "    model.summary()\n",
    "\n",
    "    # fit the model\n",
    "    history = model.fit(train_data,\n",
    "                        epochs=EPOCHS,\n",
    "                        validation_data=valid_data,\n",
    "                        steps_per_epoch=train_steps,\n",
    "                        callbacks=[callback]\n",
    "                        )\n",
    "    # print results\n",
    "    metrics = model.metrics_names\n",
    "\n",
    "    description = 'Train result:\\n'\n",
    "    train_result = model.evaluate(train_data, steps=train_steps, verbose=0);\n",
    "    description += str(list(zip(metrics, train_result))) + '\\n'\n",
    "\n",
    "    description += 'Validation result:\\n'\n",
    "    valid_result = model.evaluate(valid_data, verbose=0);\n",
    "    description += str(list(zip(metrics, valid_result))) + '\\n'\n",
    "\n",
    "    description += 'Test result:\\n'\n",
    "    test_result = model.evaluate(test_data, verbose=0);\n",
    "    description += str(list(zip(metrics, test_result))) + '\\n'\n",
    "\n",
    "    description += 'Test result only |difficulty|> 2:\\n'\n",
    "    extremes = [[i, j] for i, j in test if j > 2 or j < -2]\n",
    "    x_test_extremes, y_test_extremes = encode(extremes, tokenizer, MAX_LENGTH)\n",
    "    test_extremes_data = (\n",
    "        tf.data.Dataset\n",
    "            .from_tensor_slices((x_test_extremes, y_test_extremes))\n",
    "            .batch(BATCH_SIZE)\n",
    "            .prefetch(AUTO)\n",
    "    )\n",
    "    test_extremes_result = model.evaluate(test_extremes_data, verbose=0)\n",
    "    description += str(list(zip(metrics, test_extremes_result))) + '\\n'\n",
    "    print(description)\n",
    "\n",
    "    # append results\n",
    "    train_result_T.append(train_result)\n",
    "    valid_result_T.append(valid_result)\n",
    "    test_result_T.append(test_result)\n",
    "    test_extremes_result_T.append(test_extremes_result)\n",
    "\n",
    "# print average results\n",
    "print('train     MSE, MAE, RMSE: ',[round((x/len(seeds)),4) for x in [sum(i) for i in zip(*train_result_T)]])\n",
    "print('valid     MSE, MAE, RMSE: ',[round((x/len(seeds)),4)  for x in [sum(i) for i in zip(*valid_result_T)]])\n",
    "print('test      MSE, MAE, RMSE: ',[round((x/len(seeds)),4)  for x in [sum(i) for i in zip(*test_result_T)]])\n",
    "print('test ext. MSE, MAE, RMSE: ',[round((x/len(seeds)),4) for x in [sum(i) for i in zip(*test_extremes_result_T)]])\n",
    "\n",
    "print('')\n",
    "\n",
    "import statistics\n",
    "print('SD train     MSE, MAE, RMSE: ',[round(x,4)  for x in [statistics.stdev(i) for i in zip(*train_result_T)]])\n",
    "print('SD valid     MSE, MAE, RMSE: ',[round(x,4)   for x in [statistics.stdev(i) for i in zip(*valid_result_T)]])\n",
    "print('SD test      MSE, MAE, RMSE: ',[round(x,4)   for x in [statistics.stdev(i) for i in zip(*test_result_T)]])\n",
    "print('SD test ext. MSE, MAE, RMSE: ',[round(x,4)   for x in [statistics.stdev(i) for i in zip(*test_extremes_result_T)]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1129,
     "status": "ok",
     "timestamp": 1605115296252,
     "user": {
      "displayName": "Giovanni Aradelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzto1ysV8aaZPkZLX1nLKwD5iZBJjEQjXRrC_fAA=s64",
      "userId": "05802898670150988825"
     },
     "user_tz": -60
    },
    "id": "okRb1WFVQtad",
    "outputId": "ed9c7fa8-7f89-4aef-cfe0-1d4035a28346"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(history.history['loss'])\n",
    "ax.plot(history.history['val_loss'])\n",
    "ax.lines[1].set_linestyle(\"--\")\n",
    "\n",
    "ax.set_ylabel('Loss (MSE)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.legend(['train', 'validation'])\n",
    "ax.set_xlim([0, 21])\n",
    "ax.set_xticks([0,5,10,15,20])\n",
    "ax.set_yticks([0.2,0.4,0.6,0.8,1,1.2,1.4,1.6])\n",
    "\n",
    "plt.axvline(x=11,color='green', ls='-.', lw=0.5)\n",
    "plt.show()\n",
    "fig.savefig(\"train_val_ca_line_24.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8QeilOnYonO"
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(test_data)\n",
    "valid_predictions = model.predict(valid_data)\n",
    "train_predictions = model.predict(train_data,steps=train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1731,
     "status": "ok",
     "timestamp": 1605046092227,
     "user": {
      "displayName": "Giovanni Aradelli",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggzto1ysV8aaZPkZLX1nLKwD5iZBJjEQjXRrC_fAA=s64",
      "userId": "05802898670150988825"
     },
     "user_tz": -60
    },
    "id": "T9V-ChCvZwVp",
    "outputId": "d6d8e0d9-a063-4305-addd-473742e1910e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_test.reset_index(inplace=True)\n",
    "df_validation.reset_index(inplace=True)\n",
    "df_train.reset_index(inplace=True)\n",
    "\n",
    "df_test['predicted_difficulty'] = pd.DataFrame(test_predictions.flatten())\n",
    "df_test['split'] = 'test'\n",
    "df_validation['predicted_difficulty'] = pd.DataFrame(valid_predictions.flatten())\n",
    "df_validation['split'] = 'validation'\n",
    "df_train['predicted_difficulty'] = pd.DataFrame(train_predictions.flatten())\n",
    "df_train['split'] = 'train'\n",
    "\n",
    "results = pd.concat([df_test,df_validation,df_train])\n",
    "results.to_csv('predictions_bert.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis: '***2012-13 School Data with Affect***'\n",
    "\n",
    "Dataset from can be downloaded [here](https://drive.google.com/file/d/0BxCxNjHXlkkHczVDT2kyaTQyZUk/edit).\n",
    "\n",
    "Description of the dataset can be found on [link1](https://sites.google.com/site/assistmentsdata/home/2012-13-school-data-with-affect) , [link2](https://sites.google.com/site/assistmentsdata/how-to-interpret).\n",
    "\n",
    "    \n",
    "## Table of contents\n",
    "1. Load Dataset   \n",
    "    1.1 Dimensionality raw dataset\n",
    "2. Analysis   \n",
    "    2.1 First attempts   \n",
    "    2.2 Actions      \n",
    "    2.3 Attribute 'correct'   \n",
    "    2.4 Attribute 'problem_type'    \n",
    "    2.5 Attribute 'original'   \n",
    "    2.6 Attribute  'template_id' vs 'problem_id': unique problems   \n",
    "    2.7 Attribute  'template_id' vs 'problem_id': similarity\n",
    "3. Correctness\n",
    "    3.1 Correctness per user_id, problem_id   \n",
    "    3.2 Correctness per original vs scaffolding   \n",
    "    3.3 Correctness per problem_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:51:56.134126Z",
     "start_time": "2020-05-05T10:51:51.328723Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries,functions\n",
    "import matplotlib.pylab as pylab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#set default parameters for plotting\n",
    "params = {\n",
    "    'legend.fontsize': 'x-large',\n",
    "    'figure.figsize': (15, 15),\n",
    "    'axes.labelsize': 'x-large',\n",
    "    'axes.titlesize': 'xx-large',\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large',\n",
    "    'axes.titlepad': 20,\n",
    "    'axes.titleweight': 500,\n",
    "    'axes.labelpad': 10\n",
    "}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:51:56.164978Z",
     "start_time": "2020-05-05T10:51:56.156003Z"
    }
   },
   "outputs": [],
   "source": [
    "def percent_correct(data):\n",
    "    \"\"\"\n",
    "    :param a dataframe containing \"corrent\" column (1 ok, 0 ko)\n",
    "    :return: percentage of correct answers \n",
    "    \"\"\"\n",
    "    correct = data[(data.correct == 1)].shape[0]\n",
    "    wrong = data[(data.correct == 0)].shape[0]\n",
    "\n",
    "    support = data.shape[0]\n",
    "    result = correct / (correct + wrong)\n",
    "\n",
    "    return round(result, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <font color='blue'>1 Load Dataset</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:10.746912Z",
     "start_time": "2020-05-05T10:52:02.813674Z"
    }
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "df = pd.read_csv(r'../data/ASSISTmentsData_reduced.csv', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dimensionality of the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:16.153208Z",
     "start_time": "2020-05-05T10:53:16.141241Z"
    }
   },
   "outputs": [],
   "source": [
    "row, col = df.shape\n",
    "\n",
    "print(\"#Action: \", row)\n",
    "print(\"#Attribute: \", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:20.618305Z",
     "start_time": "2020-05-05T10:53:20.522526Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"#unique user: \", df.user_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:25.148189Z",
     "start_time": "2020-05-05T10:53:24.971627Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"#unique problem: \", df.problem_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:29.802656Z",
     "start_time": "2020-05-05T10:53:29.677982Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"#unique template: \", df.template_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:34.551880Z",
     "start_time": "2020-05-05T10:53:34.405271Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"#unique assistment: \", df.assistment_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:42.319144Z",
     "start_time": "2020-05-05T10:53:39.156564Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#missing values for each attribute\n",
    "\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>2 Analysis</font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:53:47.137879Z",
     "start_time": "2020-05-05T10:53:46.771926Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep only attributes that we will use\n",
    "df1 = df[[\n",
    "    'problem_id', 'user_id', 'problem_type', 'start_time', 'original',\n",
    "    'correct', 'template_id', 'assistment_id'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 First attempt\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "It is better to consider just the first attempt to a problem, this is done in order to estimate a true  difficulty of the questions in the next part (IRT estimation).      \n",
    "\n",
    "We are going to drop duplicates 'problem_id' 'user_id', keeping only the first one using the attribute 'start_time'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:04.375424Z",
     "start_time": "2020-04-10T20:50:59.894273Z"
    }
   },
   "outputs": [],
   "source": [
    "#check how many unique problem_id user_id exists = how many first attempts\n",
    "df1.groupby(['problem_id', 'user_id']).ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:54:29.922176Z",
     "start_time": "2020-05-05T10:54:05.223632Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"#actions before: \", df1.shape[0])\n",
    "\n",
    "#order rows by start time\n",
    "df1.sort_values('start_time', inplace=True)\n",
    "\n",
    "#keep the first duplicate, drop others\n",
    "df1.drop_duplicates(subset=['problem_id', 'user_id'],\n",
    "                    keep='first',\n",
    "                    inplace=True)\n",
    "\n",
    "print(\"#actions after: \", df1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Actions\n",
    "\n",
    "\n",
    "**Description**\n",
    "\n",
    "A row in the dataset represents an action (i.e the answer of a user_id to a problem_id), each action is identified by a different problem_log_id\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:31.108940Z",
     "start_time": "2020-04-10T20:51:30.877048Z"
    }
   },
   "outputs": [],
   "source": [
    "# actions x user\n",
    "# equivalent: problems x user (since we have only first attempt, pair user_id, problem_id is unique)\n",
    "action_user = df1.user_id.value_counts()\n",
    "mean = action_user.mean(axis=0)\n",
    "std = action_user.std(axis=0)\n",
    "\n",
    "print(\"actions x user mean: \", mean)\n",
    "print(\"actions x user std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:31.522390Z",
     "start_time": "2020-04-10T20:51:31.111930Z"
    }
   },
   "outputs": [],
   "source": [
    "# actions x problem\n",
    "# equivalent: students x problem \n",
    "\n",
    "action_problem = df1.problem_id.value_counts()\n",
    "mean = action_problem.mean(axis=0)\n",
    "std = action_problem.std(axis=0)\n",
    "\n",
    "print(\"actions x problem mean: \", mean)\n",
    "print(\"actions x problem std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:31.767733Z",
     "start_time": "2020-04-10T20:51:31.526379Z"
    }
   },
   "outputs": [],
   "source": [
    "# actions x template\n",
    "\n",
    "action_template = df1.template_id.value_counts()\n",
    "mean = action_template.mean(axis=0)\n",
    "std = action_template.std(axis=0)\n",
    "\n",
    "print(\"actions x template mean: \", mean)\n",
    "print(\"actions x template std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:32.145721Z",
     "start_time": "2020-04-10T20:51:31.772720Z"
    }
   },
   "outputs": [],
   "source": [
    "# actions x assistment\n",
    "\n",
    "action_assistment = df1.assistment_id.value_counts()\n",
    "mean = action_assistment.mean(axis=0)\n",
    "std = action_assistment.std(axis=0)\n",
    "\n",
    "print(\"actions x assistment mean: \", mean)\n",
    "print(\"actions x assistment std: \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:32.164671Z",
     "start_time": "2020-04-10T20:51:32.148714Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep problem/user with interacations greater than a threshold t\n",
    "# looking at this it's important to see how many problem/user are statistically significant for next step (IRT est)\n",
    "\n",
    "t = 50\n",
    "u = action_user[action_user > t].size\n",
    "p = action_problem[action_problem > t].size\n",
    "\n",
    "print(u, \" users with #actions greater than \", t)\n",
    "print(p, \" problems with #actions greater than \", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T16:16:36.558721Z",
     "start_time": "2020-04-27T16:16:36.527805Z"
    }
   },
   "source": [
    "## 2.X Attribute ***'start_time'***\n",
    "--------------------------------------------------------------------------\n",
    "**Description**\n",
    "\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:54:39.024757Z",
     "start_time": "2020-05-05T10:54:35.063330Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"min start_time: \",df1.start_time.min())\n",
    "print(\"max start_time: \",df1.start_time.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:57:21.023653Z",
     "start_time": "2020-05-05T10:57:08.461530Z"
    }
   },
   "outputs": [],
   "source": [
    "df_time = df1.groupby(['user_id'])['start_time'].agg([('Min' , 'min'), ('Max', 'max')]).add_prefix('Day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:57:26.014314Z",
     "start_time": "2020-05-05T10:57:25.913572Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_time['DayMax'] = pd.to_datetime(df_time['DayMax'])\n",
    "df_time['DayMin'] = pd.to_datetime(df_time['DayMin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:57:30.599041Z",
     "start_time": "2020-05-05T10:57:30.588072Z"
    }
   },
   "outputs": [],
   "source": [
    "diff =df_time['DayMax']-df_time['DayMin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:55:13.362992Z",
     "start_time": "2020-05-05T10:55:13.336067Z"
    }
   },
   "outputs": [],
   "source": [
    "diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:57:35.119895Z",
     "start_time": "2020-05-05T10:57:35.101944Z"
    }
   },
   "outputs": [],
   "source": [
    "diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:44:36.366222Z",
     "start_time": "2020-04-27T17:44:30.585682Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep only attributes that we will use\n",
    "temp = df[['problem_id', 'user_id', 'assignment_id']]\n",
    "temp = temp.groupby('assignment_id').agg('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:46:59.752142Z",
     "start_time": "2020-04-27T17:46:59.743165Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.user_id.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-27T17:47:49.596712Z",
     "start_time": "2020-04-27T17:47:49.590730Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.problem_id.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Attribute ***'correct'***\n",
    "--------------------------------------------------------------------------\n",
    "**Description**\n",
    "\n",
    "■ 1 = Correct on first attempt \n",
    "  \n",
    "■ Decimal values are calculated as a partial credit based on the number of hints and attempts needed to solve (based on teacher   setting)  \n",
    "  \n",
    "■ 0 = Incorrect on first attempt, or asked for help  \n",
    "\n",
    "When observed as a dependent variable, it is recommended that this value be converted to a binary variable using the formula: 1 = correct, <1 = Incorrect\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "In order to have only binary result, round each decimal value as suggested in the ASSISTmentsData website.   \n",
    "However there are few decimal values in this field and they are associated with 'open_response' problem_type .\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:32.336230Z",
     "start_time": "2020-04-10T20:51:32.168662Z"
    }
   },
   "outputs": [],
   "source": [
    "#print counts of unique values attribute 'correct'\n",
    "df1.correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:33.136151Z",
     "start_time": "2020-04-10T20:51:32.340203Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply round to 'correct' column. ex: 0.875 --> 0\n",
    "#cast to int reduce the float to the lower inger\n",
    "df1['correct'] = df1['correct'].astype(int)\n",
    "\n",
    "#display counts attribute 'correct' after rounding\n",
    "\n",
    "x = df1.correct.value_counts(normalize=True).plot.bar()\n",
    "\n",
    "x.set_title(\"Answers\")\n",
    "x.set_xlabel(\"correct\")\n",
    "x.set_ylabel(\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Attribute ***'problem_type'***\n",
    "--------------------------------------------------------------------------\n",
    "**Description**\n",
    "\n",
    "■ choose_1: Multiple choice (radio buttons)  \n",
    "■ algebra: Math evaluated string (text box)  \n",
    "■ fill_in: Simple string-compared answer (text box)  \n",
    "■ open_response: Records student answer, but their response is always marked correct\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "Looking at the data this \"response is always marked correct\" is not true.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:34.098093Z",
     "start_time": "2020-04-10T20:51:33.141141Z"
    }
   },
   "outputs": [],
   "source": [
    "#print counts of unique values attribute 'problem_type'\n",
    "\n",
    "df1.problem_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:34.775323Z",
     "start_time": "2020-04-10T20:51:34.101086Z"
    }
   },
   "outputs": [],
   "source": [
    "#look at the distribution of correct attribute in the case of open_response\n",
    "#As we can see results are not always marked correct, so there is no need to drop these problems\n",
    "\n",
    "df1[df1.problem_type == 'open_response'].correct.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:35.982960Z",
     "start_time": "2020-04-10T20:51:34.779313Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1.problem_type.value_counts(normalize=True).plot.bar()\n",
    "\n",
    "x.set_title(\"Problem_type occurences\")\n",
    "x.set_xlabel(\"problem_type\")\n",
    "x.set_ylabel(\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Attribute 'Original'\n",
    "\n",
    "\n",
    "**Description**\n",
    "\n",
    "■ 1 = Main problem   \n",
    "  \n",
    "■ 0 = Scaffolding problem   \n",
    "\n",
    "If a problem has scaffolding and the student answers incorrectly or asks for the problem to be broken into steps, a new problem will be created called a scaffolding problem. This creates a separate problem log row in the file with the variable original = 0.\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "Around 30% problems are scaffolding, in the next section we will analyze the difference in term of correctness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:36.362511Z",
     "start_time": "2020-04-10T20:51:35.993932Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1.correct.value_counts(normalize=True).plot.bar()\n",
    "\n",
    "x.set_title(\"Original vs Scaffolding\")\n",
    "x.set_xlabel(\"original\")\n",
    "x.set_ylabel(\"%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Attribute 'template_id' vs 'problem_id': unique problems\n",
    "\n",
    "\n",
    "**Description**\n",
    "\n",
    "The template ID of the ASSISTment. ASSISTments with the same template ID have similar questions.   \n",
    "\n",
    "How many problem are unique, not derived from a template? (i.e. how many template has associated only ONE problem_id)  \n",
    "\n",
    "Example:   Consider this action table\n",
    "\n",
    "| template_id | problem_id   |\n",
    "|------|------|\n",
    "|   12  | 2|\n",
    "|   12  | 4|\n",
    "|   3  | 5|\n",
    "|   3  | 5|\n",
    "|   10  | 8|\n",
    "|   10  | 9|\n",
    "\n",
    "\n",
    "Problem_id 5 is unique, since his template_id appears always associated with problem_id 5   \n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "**Consideration**\n",
    "\n",
    "Around half of the problems do not derive from a template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:37.080075Z",
     "start_time": "2020-04-10T20:51:36.368497Z"
    }
   },
   "outputs": [],
   "source": [
    "back = df1.copy()\n",
    "back = back[['problem_id', 'template_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:37.854510Z",
     "start_time": "2020-04-10T20:51:37.083067Z"
    }
   },
   "outputs": [],
   "source": [
    "# keep only unique pair problem_id, template_id (keep order doesn't matter)\n",
    "back = back.drop_duplicates(['problem_id', 'template_id'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:37.889416Z",
     "start_time": "2020-04-10T20:51:37.858501Z"
    }
   },
   "outputs": [],
   "source": [
    "# now a template_id that appears more than 1 times is a template that has associated more than 1 problem_id\n",
    "f = back.template_id.value_counts().values\n",
    "\n",
    "# count the how many template_id has associated only 1 problem_id\n",
    "unique = np.count_nonzero(f == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:38.053248Z",
     "start_time": "2020-04-10T20:51:37.893408Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"# total problems: \", df1.problem_id.nunique())\n",
    "print(\"# unique problems: \", unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Attribute 'template_id' vs 'problem_id':  similarity \n",
    "\n",
    "**Description**\n",
    "\n",
    "We want to verify if problems from the same template presents the almost same correctness.\n",
    "\n",
    "Procedure:   \n",
    "    1) keep problem_id with at least 50 actions   (filter)   \n",
    "    2) calculate correctness associate with each problem_id (group by + aggregate f. mean)   \n",
    "    3) keep template_id with at least 10 problem_id (filter)   \n",
    "    4) calculate for each template_id the standard dev. of the problem_id associated with it (should be closest to zero)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:38.806767Z",
     "start_time": "2020-04-10T20:51:38.056242Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = df1.copy()\n",
    "temp = temp[['problem_id','template_id','correct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:40.851360Z",
     "start_time": "2020-04-10T20:51:38.810757Z"
    }
   },
   "outputs": [],
   "source": [
    "#drop actions associated with problem with less than 50 actions\n",
    "\n",
    "print(\"#problem before: \", temp.problem_id.nunique())\n",
    "print(\"#action before: \", temp.shape[0])\n",
    "temp = temp[\n",
    "    temp['problem_id'].groupby(temp['problem_id']).transform('size') > 50]\n",
    "\n",
    "print(\"#problem after: \", temp.problem_id.nunique())\n",
    "print(\"#action after: \", temp.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:41.336063Z",
     "start_time": "2020-04-10T20:51:40.854352Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each unique problem_id calculate the correctness (that is the mean of the correct value)\n",
    "temp = temp.groupby('problem_id').agg('mean')\n",
    "\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:41.368977Z",
     "start_time": "2020-04-10T20:51:41.340053Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop template_id that has less than 10 problems associated\n",
    "print(\"#template before: \", temp.template_id.nunique())\n",
    "\n",
    "temp = temp[\n",
    "    temp['template_id'].groupby(temp['template_id']).transform('size') > 10]\n",
    "\n",
    "print(\"#template after: \", temp.template_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:41.389919Z",
     "start_time": "2020-04-10T20:51:41.371968Z"
    }
   },
   "outputs": [],
   "source": [
    "# for each unique template_id calculate the standard dev. of the correctness of the problems associated with it\n",
    "temp = temp.groupby('template_id').agg('std')\n",
    "\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:41.634779Z",
     "start_time": "2020-04-10T20:51:41.392911Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.boxplot(column='correct', return_type='axes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# <font color='blue'>3 Correctness</font> \n",
    "\n",
    "\n",
    "## Correctness density\n",
    "--------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Using kernel-density estimate using Gaussian kernels to estimate PDF [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.density.html?highlight=density)   \n",
    "   \n",
    "X axis: Correctness Range is [0,1]   \n",
    "Y axis: Density   \n",
    "\n",
    "\n",
    "Before proceeding, it may be better to remove problem with few actions,\n",
    "items with low actions could add noise.\n",
    "\n",
    "\n",
    "--------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T10:56:39.604224Z",
     "start_time": "2020-05-05T10:56:38.431353Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove problem_id with less than 50 actions\n",
    "df1 = df1[\n",
    "    df1['problem_id'].groupby(df1['problem_id']).transform('size') >= 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Correctness per user_id, problem_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:46.742165Z",
     "start_time": "2020-04-10T20:51:43.570615Z"
    }
   },
   "outputs": [],
   "source": [
    "#group by user_id and take the mean of correct answers\n",
    "x = df1.groupby('user_id').correct.mean().plot.density()\n",
    "\n",
    "x.set_title(\"User density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:48.041800Z",
     "start_time": "2020-04-10T20:51:46.745144Z"
    }
   },
   "outputs": [],
   "source": [
    "#group by problem_id and take the mean of correct answers\n",
    "x = df1.groupby('problem_id').correct.mean().plot.density()\n",
    "\n",
    "x.set_title(\"Problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Correctness per original vs scaffolding\n",
    "\n",
    "**Consideration**\n",
    "\n",
    "Scaffolding problem shows a greater difficulty w.r.t main problem.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:49.396070Z",
     "start_time": "2020-04-10T20:51:48.044792Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"% correct original: \",\n",
    "      percent_correct(df1[df1.original == 1]))\n",
    "print(\"% correct scaffolding: \",\n",
    "      percent_correct(df1[df1.original == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:51.303256Z",
     "start_time": "2020-04-10T20:51:49.398064Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.original == 1].groupby('problem_id').correct.mean().plot.density()\n",
    "\n",
    "x.set_title(\"Original problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:51.562563Z",
     "start_time": "2020-04-10T20:51:51.308243Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.original == 0].groupby('problem_id').correct.mean().plot.density()\n",
    "\n",
    "x.set_title(\"Scaffolding problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Correctness per problem_type\n",
    "\n",
    "**Consideration**\n",
    "\n",
    "algebra, choose_1, fill_in_1 show similar shapes (they compose 99% of the total number of problems).\n",
    "open_response, rank, choose_n show very different shapes probably due to the different nature of the problem.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:55.612193Z",
     "start_time": "2020-04-10T20:51:51.565558Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"% correct algebra: \",\n",
    "      percent_correct(df1[df1.problem_type == 'algebra']))\n",
    "print(\"% correct choose_1: \",\n",
    "      percent_correct(df1[df1.problem_type == 'choose_1']))\n",
    "print(\"% correct fill_in_1: \",\n",
    "      percent_correct(df1[df1.problem_type == 'fill_in_1']))\n",
    "print(\"% correct open_response : \",\n",
    "      percent_correct(df[df.problem_type == 'open_response']))\n",
    "print(\"% correct choose_n : \",\n",
    "      percent_correct(df[df.problem_type == 'choose_n']))\n",
    "print(\"% correct rank : \",\n",
    "      percent_correct(df[df.problem_type == 'rank']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:57.033275Z",
     "start_time": "2020-04-10T20:51:55.615206Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'algebra'].groupby('problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"algebra problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:58.032445Z",
     "start_time": "2020-04-10T20:51:57.036233Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'choose_1'].groupby('problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"choose_1 problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:58.768085Z",
     "start_time": "2020-04-10T20:51:58.035439Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'fill_in_1'].groupby('problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"fill_in_1 problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:59.366543Z",
     "start_time": "2020-04-10T20:51:58.771080Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'open_response'].groupby('problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"open_response problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:51:59.925085Z",
     "start_time": "2020-04-10T20:51:59.369535Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'choose_n'].groupby('problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"choose_n problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-10T20:52:00.496057Z",
     "start_time": "2020-04-10T20:51:59.927042Z"
    }
   },
   "outputs": [],
   "source": [
    "x = df1[df1.problem_type == 'rank'].groupby(\n",
    "    'problem_id').correct.mean().plot.density(bw_method=0.2)\n",
    "\n",
    "x.set_title(\"rank problem density correctness\")\n",
    "x.set_xlabel(\"Correctness\")\n",
    "x.set_xticks([0, 0.25, 0.50, 0.75, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
